# Whole-Body Control + Object Interaction + Navigation

객체 상호작용, 이동, 제어의 통합 - Loco-manipulation with scene interaction

---

## OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction

**Links**:
- 📄 arXiv: TBA
- 🌐 Project Page: TBA

### 요약 (Summary)

**English**: OmniRetarget presents a method for interaction-preserving data generation for humanoid whole-body loco-manipulation and scene interaction. The system ensures that when human motion data is retargeted to humanoid robots, the interaction characteristics with objects and the environment are preserved, enabling more realistic and functional motion transfer.

**한글**: OmniRetarget은 휴머노이드 전신 로코-매니퓰레이션 및 장면 상호작용을 위한 상호작용 보존 데이터 생성 방법을 제시합니다. 시스템은 인간 동작 데이터가 휴머노이드 로봇에 리타게팅될 때 물체 및 환경과의 상호작용 특성이 보존되도록 하여 더 현실적이고 기능적인 모션 전이를 가능하게 합니다.

### Key Features
- Interaction-preserving retargeting
- Whole-body loco-manipulation
- Scene interaction capabilities
- Contact-aware motion transfer
- Realistic human-to-humanoid mapping

---

## DreamControl: Human-Inspired Whole-Body Humanoid Control for Scene Interaction via Guided Diffusion

**Authors**: Dvij Kalaria, Sudarshan Harithas, Pushkal Katara, Sangkyung Kwak, Sarthak Bhagat, S. Shankar Sastry, Srinath Sridhar, Sai Vemprala, Ashish Kapoor, Jonathan Huang

**Links**:
- 📄 [arXiv](https://arxiv.org/abs/2509.14353)
- 🌐 [Project Page](https://genrobo.github.io/DreamControl/)
- 💻 GitHub: TBA (Coming Soon)

### 요약 (Summary)

**English**: DreamControl introduces a novel methodology for learning autonomous whole-body humanoid skills. DreamControl leverages the strengths of diffusion models and Reinforcement Learning (RL): the core innovation is the use of a diffusion prior trained on human motion data, which subsequently guides an RL policy in simulation to complete specific tasks of interest (e.g., opening a drawer or picking up an object). The system demonstrates that this human motion-informed prior allows RL to discover solutions unattainable by direct RL, and that diffusion models inherently promote natural-looking motions, aiding in sim-to-real transfer. DreamControl validates its effectiveness on a Unitree G1 robot across diverse challenging tasks involving simultaneous lower and upper body control and object interaction, including opening drawers, bimanual picking, pressing buttons, and more.

**한글**: DreamControl은 자율 전신 휴머노이드 기술 학습을 위한 새로운 방법론을 소개합니다. DreamControl은 확산 모델과 강화학습(RL)의 강점을 활용합니다: 핵심 혁신은 인간 동작 데이터로 훈련된 확산 사전을 사용하는 것이며, 이는 시뮬레이션에서 RL 정책을 안내하여 특정 관심 작업(예: 서랍 열기 또는 물체 집기)을 완료하도록 합니다. 시스템은 이 인간 동작 정보가 담긴 사전이 RL이 직접 RL로는 달성할 수 없는 솔루션을 발견할 수 있게 하고, 확산 모델이 본질적으로 자연스러운 동작을 촉진하여 실제-실제 전이를 돕는다는 것을 보여줍니다. DreamControl은 서랍 열기, 양손 집기, 버튼 누르기 등을 포함하여 동시 하체 및 상체 제어와 물체 상호작용을 포함하는 다양한 도전적인 작업에서 Unitree G1 로봇에 대한 효과를 검증합니다.

### Key Features
- Diffusion-guided RL for humanoid control
- Human motion-informed priors
- Whole-body scene interaction
- Multiple task capabilities (drawer, picking, button pressing)
- Natural motion generation
- Sim-to-real transfer
- OmniControl diffusion model integration

---

## HDMI: Learning Interactive Humanoid Whole-Body Control from Human Videos

**Authors**: Haoyang Weng, Yitang Li, Nikhil Sobanbabu, Zihan Wang, Zhengyi Luo, Tairan He, Deva Ramanan, Guanya Shi

**Links**:
- 📄 arXiv: arXiv:2509.16757v3
- 🌐 Project Page: TBA

### 요약 (Summary)

**English**: HDMI presents a framework for learning interactive humanoid whole-body control from human videos. The system leverages large-scale human video data to learn interactive behaviors, enabling humanoids to understand and replicate complex human-object and human-scene interactions observed in videos.

**한글**: HDMI는 인간 비디오로부터 상호작용적 휴머노이드 전신 제어를 학습하는 프레임워크를 제시합니다. 시스템은 대규모 인간 비디오 데이터를 활용하여 상호작용 행동을 학습하고, 휴머노이드가 비디오에서 관찰된 복잡한 인간-물체 및 인간-장면 상호작용을 이해하고 재현할 수 있게 합니다.

### Key Features
- Learning from human videos
- Interactive whole-body control
- Scene interaction capabilities
- Video-based skill learning
- Human-object interaction understanding

---

[Back to Main README](../README.md)
