# Whole-Body Control + Object Interaction + Navigation

ê°ì²´ ìƒí˜¸ì‘ìš©, ì´ë™, ì œì–´ì˜ í†µí•© - Loco-manipulation with scene interaction

---

## OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/pdf/2509.26633)
- ğŸŒ [Project](https://omniretarget.github.io/)
- ğŸ’» GitHub: TBA (Coming Soon)
### ìš”ì•½ (Summary)

 OmniRetarget presents a method for interaction-preserving data generation for humanoid whole-body loco-manipulation and scene interaction. The system ensures that when human motion data is retargeted to humanoid robots, the interaction characteristics with objects and the environment are preserved, enabling more realistic and functional motion transfer.

 OmniRetargetì€ íœ´ë¨¸ë…¸ì´ë“œ ì „ì‹  ë¡œì½”-ë§¤ë‹ˆí“°ë ˆì´ì…˜ ë° ì¥ë©´ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ìƒí˜¸ì‘ìš© ë³´ì¡´ ë°ì´í„° ìƒì„± ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ ì¸ê°„ ë™ì‘ ë°ì´í„°ê°€ íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ì— ë¦¬íƒ€ê²ŒíŒ…ë  ë•Œ ë¬¼ì²´ ë° í™˜ê²½ê³¼ì˜ ìƒí˜¸ì‘ìš© íŠ¹ì„±ì´ ë³´ì¡´ë˜ë„ë¡ í•˜ì—¬ ë” í˜„ì‹¤ì ì´ê³  ê¸°ëŠ¥ì ì¸ ëª¨ì…˜ ì „ì´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

### Key Features
- Interaction-preserving retargeting
- Whole-body loco-manipulation
- Scene interaction capabilities
- Contact-aware motion transfer
- Realistic human-to-humanoid mapping

---



## HDMI: Learning Interactive Humanoid Whole-Body Control from Human Videos

**Authors**: Haoyang Weng, Yitang Li, Nikhil Sobanbabu, Zihan Wang, Zhengyi Luo, Tairan He, Deva Ramanan, Guanya Shi

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2509.16757)
- ğŸŒ [Project](https://hdmi-humanoid.github.io/#/)
- ğŸ’» [GitHub](https://github.com/LeCAR-Lab/HDMI)

### ìš”ì•½ (Summary)

 HDMI presents a framework for learning interactive humanoid whole-body control from human videos. The system leverages large-scale human video data to learn interactive behaviors, enabling humanoids to understand and replicate complex human-object and human-scene interactions observed in videos.

 HDMIëŠ” ì¸ê°„ ë¹„ë””ì˜¤ë¡œë¶€í„° ìƒí˜¸ì‘ìš©ì  íœ´ë¨¸ë…¸ì´ë“œ ì „ì‹  ì œì–´ë¥¼ í•™ìŠµí•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ ëŒ€ê·œëª¨ ì¸ê°„ ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ìƒí˜¸ì‘ìš© í–‰ë™ì„ í•™ìŠµí•˜ê³ , íœ´ë¨¸ë…¸ì´ë“œê°€ ë¹„ë””ì˜¤ì—ì„œ ê´€ì°°ëœ ë³µì¡í•œ ì¸ê°„-ë¬¼ì²´ ë° ì¸ê°„-ì¥ë©´ ìƒí˜¸ì‘ìš©ì„ ì´í•´í•˜ê³  ì¬í˜„í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

### Key Features
- Learning from human videos
- Interactive whole-body control
- Scene interaction capabilities
- Video-based skill learning
- Human-object interaction understanding

---

## Unleashing Humanoid Reaching Potential via Real-world-Ready Skill Space

**Authors**: Zhikai Zhang, Chao Chen, Han Xue, Jilong Wang, Sikai Liang, Yun Liu, Zongzhang Zhang, He Wang, Li Yi

**Year**: 2025

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2505.10918)
- ğŸŒ [Project](https://zzk273.github.io/R2S2/)
- ğŸ’» [GitHub](https://github.com/GalaxyGeneralRobotics/OpenWBT)

### ìš”ì•½ (Summary)

 This work presents a framework for unleashing humanoid reaching potential through a real-world-ready skill space. The system enables humanoids to perform diverse reaching and manipulation tasks with high precision and adaptability. By learning in a structured skill space, the humanoid can generalize to various reaching scenarios and object interactions.

 ì´ ì—°êµ¬ëŠ” ì‹¤ì œ ì„¸ê³„ ì¤€ë¹„ê°€ ëœ ê¸°ìˆ  ê³µê°„ì„ í†µí•´ íœ´ë¨¸ë…¸ì´ë“œì˜ ë„ë‹¬ ì ì¬ë ¥ì„ ë°œíœ˜í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ íœ´ë¨¸ë…¸ì´ë“œê°€ ë†’ì€ ì •ë°€ë„ì™€ ì ì‘ì„±ìœ¼ë¡œ ë‹¤ì–‘í•œ ë„ë‹¬ ë° ì¡°ì‘ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. êµ¬ì¡°í™”ëœ ê¸°ìˆ  ê³µê°„ì—ì„œ í•™ìŠµí•¨ìœ¼ë¡œì¨ íœ´ë¨¸ë…¸ì´ë“œëŠ” ë‹¤ì–‘í•œ ë„ë‹¬ ì‹œë‚˜ë¦¬ì˜¤ì™€ ë¬¼ì²´ ìƒí˜¸ì‘ìš©ì— ì¼ë°˜í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Key Features
- Real-world-ready skill space
- Diverse reaching capabilities
- High-precision manipulation
- Adaptive task execution
- Structured skill learning
- Generalization to various scenarios

---

## AMO: Adaptive Motion Optimization for Hyper-Dexterous Humanoid Whole-Body Control

**Authors**: Jialong Li, Xuxin Cheng, Tianshu Huang, Shiqi Yang, Ri-Zhao Qiu, Xiaolong Wang

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2505.03738)
- ğŸŒ [Project](https://amo-humanoid.github.io/)
- ğŸ’» [GitHub](https://github.com/OpenTeleVision/AMO)

### ìš”ì•½ (Summary)

 AMO introduces adaptive motion optimization for hyper-dexterous humanoid whole-body control. The system optimizes motion in real-time to achieve highly dexterous manipulation while maintaining whole-body balance and coordination.

 AMOëŠ” ì´ˆì •ë°€ íœ´ë¨¸ë…¸ì´ë“œ ì „ì‹  ì œì–´ë¥¼ ìœ„í•œ ì ì‘í˜• ëª¨ì…˜ ìµœì í™”ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ ì „ì‹  ê· í˜•ê³¼ í˜‘ì‘ì„ ìœ ì§€í•˜ë©´ì„œ ë§¤ìš° ì •ë°€í•œ ì¡°ì‘ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ì…˜ì„ ìµœì í™”í•©ë‹ˆë‹¤.

### Key Features
- Real-time motion optimization
- Hyper-dexterous manipulation capabilities
- Adaptive whole-body control
- Balance maintenance during manipulation

---

## HumanPlus: Humanoid Shadowing and Imitation from Humans

**Authors**: Zipeng Fu, Qingqing Zhao, Qi Wu, Gordon Wetzstein, Chelsea Finn

**Conference**: CoRL 2024

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2406.10454)
- ğŸŒ [Project](https://humanoid-ai.github.io/)
- ğŸ’» [GitHub](https://github.com/MarkFzp/humanplus)

### ìš”ì•½ (Summary)

 HumanPlus introduces a full-stack system for humanoids to learn motion and autonomous skills from human data. It first trains a low-level policy in simulation via RL using existing 40-hour human motion datasets. This policy transfers to the real world and allows humanoid robots to follow human body and hand motion in real time using only an RGB camera (shadowing). Through shadowing, operators can teleoperate humanoids to collect whole-body data for learning different tasks. The system demonstrates autonomous completion of tasks such as wearing a shoe to stand up and walk, unloading objects from warehouse racks, folding a sweatshirt, rearranging objects, typing, and greeting another robot with 60-100% success rates using up to 40 demonstrations.

 HumanPlusëŠ” íœ´ë¨¸ë…¸ì´ë“œê°€ ì¸ê°„ ë°ì´í„°ë¡œë¶€í„° ë™ì‘ ë° ììœ¨ ê¸°ìˆ ì„ í•™ìŠµí•˜ëŠ” í’€ìŠ¤íƒ ì‹œìŠ¤í…œì„ ì†Œê°œí•©ë‹ˆë‹¤. ë¨¼ì € ê¸°ì¡´ 40ì‹œê°„ ë¶„ëŸ‰ì˜ ì¸ê°„ ë™ì‘ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ì—ì„œ RLì„ í†µí•´ ì €ìˆ˜ì¤€ ì •ì±…ì„ í›ˆë ¨í•©ë‹ˆë‹¤. ì´ ì •ì±…ì€ ì‹¤ì œ ì„¸ê³„ë¡œ ì „ì´ë˜ì–´ íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ì´ RGB ì¹´ë©”ë¼ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸ê°„ì˜ ì‹ ì²´ì™€ ì† ë™ì‘ì„ ë”°ë¼í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤(ì„€ë„ì‰). ì„€ë„ì‰ì„ í†µí•´ ìš´ì˜ìëŠ” íœ´ë¨¸ë…¸ì´ë“œë¥¼ ì›ê²©ì¡°ì‘í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ì—… í•™ìŠµì„ ìœ„í•œ ì „ì‹  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì€ ì‹ ë°œ ì‹ ê³  ì¼ì–´ë‚˜ ê±·ê¸°, ì°½ê³  ë™ì—ì„œ ë¬¼ê±´ ë‚´ë¦¬ê¸°, ìš´ë™ë³µ ì ‘ê¸°, ë¬¼ê±´ ì¬ë°°ì¹˜, íƒ€ì´í•‘, ë‹¤ë¥¸ ë¡œë´‡ê³¼ ì¸ì‚¬í•˜ê¸° ë“±ì˜ ì‘ì—…ì„ ìµœëŒ€ 40ê°œì˜ ì‹œì—°ì„ ì‚¬ìš©í•˜ì—¬ 60-100% ì„±ê³µë¥ ë¡œ ììœ¨ ì™„ë£Œí•©ë‹ˆë‹¤.

### Key Features
- Humanoid Shadowing Transformer (HST) for low-level control
- Humanoid Imitation Transformer (HIT) for skill learning
- 40+ hours of human motion data training
- RGB camera-only shadowing system
- 33-DoF 180cm humanoid platform
- Real-world task completion (60-100% success rates)

---


[Back to Main README](../README.md)
