# Whole-Body Control + Locomotion

ì „ì‹  ì œì–´ì™€ ì´ë™ì˜ í†µí•© - Integration of manipulation and walking

---

## Expert-Guided Imitation for Learning Humanoid Loco-Manipulation from Motion Capture

**Authors**: Rohan P. Singh, Pierre-Alexandre Leziart, Masaki Murooka, Mitsuharu Morisawa, Eiichi Yoshida, Fumio Kanehiro

**Links**:
- ğŸ“„ arXiv: TBA
- ğŸŒ Project Page: TBA

### ìš”ì•½ (Summary)

**English**: This work presents an expert-guided imitation learning framework for humanoid loco-manipulation from motion capture data. The system combines locomotion and manipulation skills learned from human demonstrations, enabling humanoids to perform coordinated whole-body tasks while moving.

**í•œê¸€**: ì´ ì—°êµ¬ëŠ” ëª¨ì…˜ ìº¡ì²˜ ë°ì´í„°ë¡œë¶€í„° íœ´ë¨¸ë…¸ì´ë“œ ë¡œì½”-ë§¤ë‹ˆí“°ë ˆì´ì…˜ì„ ìœ„í•œ ì „ë¬¸ê°€ ê°€ì´ë“œ ëª¨ë°© í•™ìŠµ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ ì¸ê°„ ì‹œì—°ìœ¼ë¡œë¶€í„° í•™ìŠµí•œ ì´ë™ê³¼ ì¡°ì‘ ê¸°ìˆ ì„ ê²°í•©í•˜ì—¬ íœ´ë¨¸ë…¸ì´ë“œê°€ ì´ë™í•˜ë©´ì„œ í˜‘ì‘ëœ ì „ì‹  ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

### Key Features
- Expert-guided imitation learning
- Motion capture-based training
- Coordinated loco-manipulation
- Whole-body skill integration
- Real-world humanoid deployment

---

## GMT: General Motion Tracking for Humanoid Whole-Body Control

**Authors**: Zixuan Chen, Mazeyu Ji, Xuxin Cheng, Xuanbin Peng, Xue Bin Peng, Xiaolong Wang

**Year**: 2025

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2506.14770)
- ğŸŒ [Project Page](https://gmt-humanoid.github.io/)
- ğŸ’» [GitHub](https://github.com/zixuan417/humanoid-general-motion-tracking)

### ìš”ì•½ (Summary)

**English**: GMT proposes a general and scalable motion-tracking framework that trains a single unified policy to enable humanoid robots to track diverse motions in the real world. GMT is built upon two core components: an Adaptive Sampling strategy and a Motion Mixture-of-Experts (MoE) architecture. The Adaptive Sampling automatically balances easy and difficult motions during training, while the MoE ensures better specialization of different regions of the motion manifold. GMT achieves state-of-the-art performance across a broad spectrum of motions using a unified general policy, including stretching, kicking, dancing, high kicking, kung-fu, boxing, running, side stepping, and squatting.

**í•œê¸€**: GMTëŠ” íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ì´ ì‹¤ì œ ì„¸ê³„ì—ì„œ ë‹¤ì–‘í•œ ë™ì‘ì„ ì¶”ì í•  ìˆ˜ ìˆë„ë¡ ë‹¨ì¼ í†µí•© ì •ì±…ì„ í›ˆë ¨í•˜ëŠ” ì¼ë°˜ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ ëª¨ì…˜ ì¶”ì  í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. GMTëŠ” ë‘ ê°€ì§€ í•µì‹¬ êµ¬ì„± ìš”ì†Œì¸ ì ì‘í˜• ìƒ˜í”Œë§ ì „ëµê³¼ ëª¨ì…˜ Mixture-of-Experts (MoE) ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ì ì‘í˜• ìƒ˜í”Œë§ì€ í›ˆë ¨ ì¤‘ ì‰¬ìš´ ë™ì‘ê³¼ ì–´ë ¤ìš´ ë™ì‘ì˜ ê· í˜•ì„ ìë™ìœ¼ë¡œ ë§ì¶”ê³ , MoEëŠ” ëª¨ì…˜ ë§¤ë‹ˆí´ë“œì˜ ë‹¤ë¥¸ ì˜ì—­ì— ëŒ€í•œ ë” ë‚˜ì€ ì „ë¬¸í™”ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤. GMTëŠ” ìŠ¤íŠ¸ë ˆì¹­, í‚¥, ëŒ„ìŠ¤, í•˜ì´ í‚¥, ì¿µí‘¸, ë³µì‹±, ë‹¬ë¦¬ê¸°, ì¸¡ë©´ ìŠ¤í…, ìŠ¤ì¿¼íŠ¸ë¥¼ í¬í•¨í•œ ê´‘ë²”ìœ„í•œ ë™ì‘ ìŠ¤í™íŠ¸ëŸ¼ì— ê±¸ì³ í†µí•© ì¼ë°˜ ì •ì±…ì„ ì‚¬ìš©í•˜ì—¬ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

### Key Features
- Unified general motion tracking policy
- Adaptive Sampling strategy for balanced training
- Motion Mixture-of-Experts (MoE) architecture
- State-of-the-art tracking performance
- Diverse motion capabilities (locomotion + acrobatics)
- Real-world deployment on Unitree G1
- Single policy for all motion types

---

## BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion

**Authors**: Qiayuan Liao, Takara E. Truong, Xiaoyu Huang, Guy Tevet, Koushil Sreenath, C. Karen Liu

**Year**: 2025

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2508.08241)
- ğŸŒ [Project Page](https://beyondmimic.github.io/)
- ğŸ’» GitHub: TBA

### ìš”ì•½ (Summary)

**English**: BeyondMimic presents a real-world framework to learn from human motions for versatile and naturalistic humanoid control via guided diffusion. The framework provides a motion tracking pipeline capable of challenging skills such as jumping spins, sprinting, and cartwheels with state-of-the-art motion quality. Moving beyond simply mimicking existing motions, BeyondMimic introduces a unified diffusion policy that enables zero-shot task-specific control at test time using simple cost functions. Deployed on hardware, BeyondMimic performs diverse tasks at test time, including waypoint navigation, joystick teleoperation, and obstacle avoidance, bridging sim-to-real motion tracking and flexible synthesis of human motion primitives for whole-body control.

**í•œê¸€**: BeyondMimicì€ ê°€ì´ë“œ í™•ì‚°ì„ í†µí•œ ë‹¤ì¬ë‹¤ëŠ¥í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ íœ´ë¨¸ë…¸ì´ë“œ ì œì–´ë¥¼ ìœ„í•´ ì¸ê°„ ë™ì‘ìœ¼ë¡œë¶€í„° í•™ìŠµí•˜ëŠ” ì‹¤ì œ ì„¸ê³„ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. í”„ë ˆì„ì›Œí¬ëŠ” ìµœì²¨ë‹¨ ëª¨ì…˜ í’ˆì§ˆë¡œ ì í”„ ìŠ¤í•€, ì „ë ¥ ì§ˆì£¼, ì¬ì£¼ë„˜ê¸°ì™€ ê°™ì€ ë„ì „ì ì¸ ê¸°ìˆ ì´ ê°€ëŠ¥í•œ ëª¨ì…˜ ì¶”ì  íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤. ê¸°ì¡´ ë™ì‘ì„ ë‹¨ìˆœíˆ ëª¨ë°©í•˜ëŠ” ê²ƒì„ ë„˜ì–´, BeyondMimicì€ ê°„ë‹¨í•œ ë¹„ìš© í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì‹œì ì— ì œë¡œìƒ· ì‘ì—…ë³„ ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í†µí•© í™•ì‚° ì •ì±…ì„ ë„ì…í•©ë‹ˆë‹¤. í•˜ë“œì›¨ì–´ì— ë°°ì¹˜ëœ BeyondMimicì€ ê²½ìœ ì§€ ë„¤ë¹„ê²Œì´ì…˜, ì¡°ì´ìŠ¤í‹± ì›ê²©ì¡°ì‘, ì¥ì• ë¬¼ íšŒí”¼ë¥¼ í¬í•¨í•œ ë‹¤ì–‘í•œ ì‘ì—…ì„ í…ŒìŠ¤íŠ¸ ì‹œì ì— ìˆ˜í–‰í•˜ì—¬ ì „ì‹  ì œì–´ë¥¼ ìœ„í•œ ì‹¤ì œ-ì‹¤ì œ ëª¨ì…˜ ì¶”ì ê³¼ ì¸ê°„ ëª¨ì…˜ í”„ë¦¬ë¯¸í‹°ë¸Œì˜ ìœ ì—°í•œ í•©ì„±ì„ ì—°ê²°í•©ë‹ˆë‹¤.

### Key Features
- Scalable motion tracking pipeline
- Guided diffusion for policy synthesis
- State-of-the-art motion quality
- Zero-shot task adaptation at test time
- Challenging skills (jumping spins, sprinting, cartwheels)
- Real-world deployment on Unitree G1
- Unified diffusion policy for diverse tasks
- Cost function-based guidance

---

[Back to Main README](../README.md)
