# Whole-Body Control + VLA (Vision-Language-Action)

ë¹„ì „-ì–¸ì–´-í–‰ë™ ëª¨ë¸ ê¸°ë°˜ ì œì–´ - Vision-Language-Action models for humanoid control

---

## LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2506.13751)
- ğŸŒ [Project](https://ember-lab-berkeley.github.io/LeVERB-Website/)
- ğŸ’» GitHub: TBA (Coming Soon)
### ìš”ì•½ (Summary)

 LeVERB introduces humanoid whole-body control with latent vision-language instruction. The system uses latent representations learned from vision and language to guide humanoid control, enabling more robust and generalizable behavior across diverse tasks and environments.

 LeVERBëŠ” ì ì¬ ë¹„ì „-ì–¸ì–´ ì§€ì‹œë¥¼ ì‚¬ìš©í•œ íœ´ë¨¸ë…¸ì´ë“œ ì „ì‹  ì œì–´ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ ë¹„ì „ê³¼ ì–¸ì–´ë¡œë¶€í„° í•™ìŠµí•œ ì ì¬ í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ íœ´ë¨¸ë…¸ì´ë“œ ì œì–´ë¥¼ ì•ˆë‚´í•˜ë©°, ë‹¤ì–‘í•œ ì‘ì—…ê³¼ í™˜ê²½ì—ì„œ ë” ê²¬ê³ í•˜ê³  ì¼ë°˜í™” ê°€ëŠ¥í•œ í–‰ë™ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

### Key Features
- Latent vision-language representations
- Multimodal instruction following
- Whole-body control integration
- Robust task generalization
- Vision-language alignment

---

## LangWBC: Language-directed Humanoid Whole-Body Control via End-to-end Learning

**Authors**: Yiyang Shao, Bike Zhang, Qiayuan Liao, Xiaoyu Huang, Yuman Gao, Yufeng Chi, Zhongyu Li, Sophia Shao, Koushil Sreenath

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2504.21738)
- ğŸŒ [Project](https://langwbc.github.io/)
- ğŸ’» [GitHub](https://github.com/YiyangShao2003/LangWBC)

### ìš”ì•½ (Summary)

 LangWBC presents a language-directed humanoid whole-body control system via end-to-end learning. The system enables users to control humanoids using natural language commands, translating high-level linguistic instructions into coordinated whole-body motions. This bridges the gap between human intent expressed through language and robot execution.

 LangWBCëŠ” ì—”ë“œíˆ¬ì—”ë“œ í•™ìŠµì„ í†µí•œ ì–¸ì–´ ì§€í–¥ íœ´ë¨¸ë…¸ì´ë“œ ì „ì‹  ì œì–´ ì‹œìŠ¤í…œì„ ì œì‹œí•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ ì‚¬ìš©ìê°€ ìì—°ì–´ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ íœ´ë¨¸ë…¸ì´ë“œë¥¼ ì œì–´í•  ìˆ˜ ìˆê²Œ í•˜ë©°, ê³ ìˆ˜ì¤€ ì–¸ì–´ ì§€ì‹œë¥¼ í˜‘ì‘ëœ ì „ì‹  ë™ì‘ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ëŠ” ì–¸ì–´ë¥¼ í†µí•´ í‘œí˜„ëœ ì¸ê°„ì˜ ì˜ë„ì™€ ë¡œë´‡ ì‹¤í–‰ ì‚¬ì´ì˜ ê²©ì°¨ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.

### Key Features
- Natural language control interface
- End-to-end learning framework
- High-level command interpretation
- Whole-body motion generation from language
- Language-to-action translation

---




[Back to Main README](../README.md)
