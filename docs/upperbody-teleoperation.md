# Upper-Body Oriented Teleoperation

ìƒì²´ ì¤‘ì‹¬ì˜ ì›ê²©ì¡°ì‘ ì‹œìŠ¤í…œ - Focusing on arm and hand manipulation

---

## ACE: A Cross-Platform Visual-Exoskeletons System for Low-Cost Dexterous Teleoperation

**Authors**: Shiqi Yang, Minghuan Liu, Yuzhe Qin, Runyu Ding, Jialong Li, Xuxin Cheng, Ruihan Yang, Sha Yi, Xiaolong Wang

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2408.11805)
- ğŸŒ [Project Page](https://ace-teleop.github.io/)
- ğŸ’» GitHub: TBA

### ìš”ì•½ (Summary)

**English**: ACE is a cross-platform visual-exoskeleton system for low-cost dexterous teleoperation. It utilizes a hand-facing camera to capture 3D hand poses and an exoskeleton mounted on a portable base, enabling accurate real-time capture of both finger and wrist poses. The system can generalize to humanoid hands, arm-hands, arm-gripper, and quadruped-gripper systems with high-precision teleoperation.

**í•œê¸€**: ACEëŠ” ì €ë¹„ìš© ì •ë°€ ì›ê²©ì¡°ì‘ì„ ìœ„í•œ í¬ë¡œìŠ¤ í”Œë«í¼ ë¹„ì£¼ì–¼-ì—‘ì†ŒìŠ¤ì¼ˆë ˆí†¤ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì†ì„ í–¥í•œ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ì—¬ 3D ì† í¬ì¦ˆë¥¼ ìº¡ì²˜í•˜ê³  íœ´ëŒ€ìš© ë² ì´ìŠ¤ì— ì¥ì°©ëœ ì—‘ì†ŒìŠ¤ì¼ˆë ˆí†¤ì„ í†µí•´ ì†ê°€ë½ê³¼ ì†ëª© í¬ì¦ˆë¥¼ ì •í™•í•˜ê²Œ ì‹¤ì‹œê°„ìœ¼ë¡œ ìº¡ì²˜í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ íœ´ë¨¸ë…¸ì´ë“œ ì†, íŒ”-ì†, íŒ”-ê·¸ë¦¬í¼, ì‚¬ì¡±ë³´í–‰ ë¡œë´‡-ê·¸ë¦¬í¼ ì‹œìŠ¤í…œì— ë²”ìš©ì ìœ¼ë¡œ ì ìš© ê°€ëŠ¥í•˜ë©° ê³ ì •ë°€ ì›ê²©ì¡°ì‘ì„ ì œê³µí•©ë‹ˆë‹¤.

### Key Features
- Cross-platform compatibility across different robot types
- Low-cost design ($1,000-2,000 range)
- 3D hand pose estimation from RGB camera
- Portable exoskeleton system
- High-precision finger and wrist tracking

---

## DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills

**Authors**: Xue Bin Peng, Pieter Abbeel, Sergey Levine, Michiel van de Panne

**Links**:
- ğŸ“„ arXiv: TBA
- ğŸŒ Project Page: TBA

### ìš”ì•½ (Summary)

**English**: DeepMimic presents a data-driven approach to physics-based character animation using deep reinforcement learning. The system learns to imitate reference motion clips through RL, enabling characters to perform a wide variety of challenging skills including locomotion, acrobatics, and martial arts.

**í•œê¸€**: DeepMimicì€ ì‹¬ì¸µ ê°•í™”í•™ìŠµì„ ì‚¬ìš©í•œ ë¬¼ë¦¬ ê¸°ë°˜ ìºë¦­í„° ì• ë‹ˆë©”ì´ì…˜ì— ëŒ€í•œ ë°ì´í„° ê¸°ë°˜ ì ‘ê·¼ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ RLì„ í†µí•´ ì°¸ì¡° ëª¨ì…˜ í´ë¦½ì„ ëª¨ë°©í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•˜ì—¬ ìºë¦­í„°ê°€ ë³´í–‰, ê³¡ì˜ˆ, ë¬´ìˆ ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ë„ì „ì ì¸ ê¸°ìˆ ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

### Key Features
- Physics-based character control
- Example-guided reinforcement learning
- Diverse skill learning (locomotion, acrobatics, martial arts)
- Motion imitation framework
- Deep RL for character animation

---

## Diffuse-CLoC: Guided Diffusion for Physics-based Character Look-ahead Control

**Authors**: Xiaoyu Huang, Takara Truong, Yunbo Zhang, Fangzhou Yu, Jean-Pierre Sleiman, Jessica Hodgins, K. Sreenath, Farbod Farshidian

**Links**:
- ğŸ“„ arXiv: TBA
- ğŸŒ Project Page: TBA

### ìš”ì•½ (Summary)

**English**: Diffuse-CLoC introduces a guided diffusion approach for physics-based character control. The method combines diffusion models with look-ahead control to generate realistic and physically plausible character motions.

**í•œê¸€**: Diffuse-CLoCì€ ë¬¼ë¦¬ ê¸°ë°˜ ìºë¦­í„° ì œì–´ë¥¼ ìœ„í•œ ê°€ì´ë“œ í™•ì‚° ì ‘ê·¼ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ í™•ì‚° ëª¨ë¸ê³¼ ì„ í–‰ ì œì–´ë¥¼ ê²°í•©í•˜ì—¬ í˜„ì‹¤ì ì´ê³  ë¬¼ë¦¬ì ìœ¼ë¡œ íƒ€ë‹¹í•œ ìºë¦­í„° ë™ì‘ì„ ìƒì„±í•©ë‹ˆë‹¤.

### Key Features
- Guided diffusion for character control
- Physics-based motion generation
- Look-ahead control mechanism
- Realistic character animation

---

## MaskedManipulator: Versatile Whole-Body Manipulation

**Authors**: Chen Tessler, Yifeng Jiang, Erwin Coumans, Zhengyi Luo, Gal Chechik, Xue Bin Peng

**Conference**: SA Conference Papers '25, Hong Kong

**Links**:
- ğŸ“„ arXiv: TBA
- ğŸŒ Project Page: TBA

### ìš”ì•½ (Summary)

**English**: MaskedManipulator presents a versatile whole-body manipulation framework using masked motion learning. The system enables robots to perform complex manipulation tasks by learning from masked human motion data.

**í•œê¸€**: MaskedManipulatorëŠ” ë§ˆìŠ¤í¬ëœ ëª¨ì…˜ í•™ìŠµì„ ì‚¬ìš©í•œ ë‹¤ëª©ì  ì „ì‹  ì¡°ì‘ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ë§ˆìŠ¤í¬ëœ ì¸ê°„ ë™ì‘ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµí•˜ì—¬ ë¡œë´‡ì´ ë³µì¡í•œ ì¡°ì‘ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

### Key Features
- Masked motion learning approach
- Versatile manipulation capabilities
- Whole-body coordination
- Learning from human demonstrations

---

[Back to Main README](../README.md)
