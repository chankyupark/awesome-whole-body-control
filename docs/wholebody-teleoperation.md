# Whole-Body Oriented Teleoperation

ì „ì‹  í˜‘ì‘ ì›ê²©ì¡°ì‘ ì‹œìŠ¤í…œ - Coordinated full-body control systems

---

## CLONE: Closed-Loop Whole-Body Humanoid Teleoperation for Long-Horizon Tasks

**Authors**: Yixuan Li, Yutang Lin, Jieming Cui, Tengyu Liu, Wei Liang, Yixin Zhu, Siyuan Huang

**Year**: 2025

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2506.08931)
- ğŸŒ [Project](https://humanoid-clone.github.io/)
- ğŸ’» [GitHub](https://github.com/humanoid-clone/CLONE/)

### ìš”ì•½ (Summary)

 CLONE is a closed-loop whole-body teleoperation system that achieves comprehensive robot control using only a VR headset. It employs a Mixture-of-Experts (MoE) architecture that learns diverse motion skills while a LiDAR-based error correction mechanism prevents the accumulation of positional drift. CLONE enables unprecedented whole-body teleoperation fidelity, maintaining minimal positional drift (5.1cm mean error over 8.9m) over long-range trajectories using only head and hand tracking from an MR headset.

 CLONEì€ VR í—¤ë“œì…‹ë§Œì„ ì‚¬ìš©í•˜ì—¬ í¬ê´„ì ì¸ ë¡œë´‡ ì œì–´ë¥¼ ë‹¬ì„±í•˜ëŠ” íë£¨í”„ ì „ì‹  ì›ê²©ì¡°ì‘ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ëª¨ì…˜ ê¸°ìˆ ì„ í•™ìŠµí•˜ëŠ” Mixture-of-Experts (MoE) ì•„í‚¤í…ì²˜ë¥¼ ì±„ìš©í•˜ë©°, LiDAR ê¸°ë°˜ ì˜¤ë¥˜ ë³´ì • ë©”ì»¤ë‹ˆì¦˜ì´ ìœ„ì¹˜ ë“œë¦¬í”„íŠ¸ ì¶•ì ì„ ë°©ì§€í•©ë‹ˆë‹¤. CLONEì€ MR í—¤ë“œì…‹ì˜ ë¨¸ë¦¬ì™€ ì† ì¶”ì ë§Œìœ¼ë¡œ ì¥ê±°ë¦¬ ê¶¤ì ì—ì„œ ìµœì†Œí•œì˜ ìœ„ì¹˜ ë“œë¦¬í”„íŠ¸(8.9mì—ì„œ 5.1cm í‰ê·  ì˜¤ë¥˜)ë¥¼ ìœ ì§€í•˜ë©° ì „ë¡€ ì—†ëŠ” ì „ì‹  ì›ê²©ì¡°ì‘ ì •í™•ë„ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

### Key Features
- MoE-based teleoperation framework
- Closed-loop error correction with LiDAR odometry
- Minimal hardware requirements (only MR headset)
- Long-horizon task capabilities (15m+ trajectories)
- Real-time coordination of upper and lower body
- CLONED dataset with augmented motion data

---

## TWIST: Teleoperated Whole-Body Imitation System

**Authors**: Yanjie Ze, Zixuan Chen, JoÃ£o Pedro AraÃºjo, Zi-ang Cao, Xue Bin Peng, Jiajun Wu, C. Karen Liu

**Year**: 2025

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2505.02833)
- ğŸŒ [Project](https://yanjieze.com/TWIST/)
- ğŸ’» [GitHub](https://github.com/YanjieZe/TWIST)

### ìš”ì•½ (Summary)

 TWIST presents a system for humanoid teleoperation through whole-body motion imitation. The system generates reference motion clips by retargeting human motion capture data to the humanoid robot, then develops a robust, adaptive, and responsive whole-body controller using a combination of reinforcement learning and behavior cloning (RL+BC). Through systematic analysis, TWIST demonstrates how incorporating privileged future motion frames and real-world motion capture data improves tracking accuracy. The system enables real-world humanoid robots to achieve unprecedented, versatile, and coordinated whole-body motor skills spanning whole-body manipulation, legged manipulation, locomotion, and expressive movement using a single unified neural network controller.

 TWISTëŠ” ì „ì‹  ë™ì‘ ëª¨ë°©ì„ í†µí•œ íœ´ë¨¸ë…¸ì´ë“œ ì›ê²©ì¡°ì‘ ì‹œìŠ¤í…œì„ ì œì‹œí•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ ì¸ê°„ ëª¨ì…˜ ìº¡ì²˜ ë°ì´í„°ë¥¼ íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ì— ë¦¬íƒ€ê²ŒíŒ…í•˜ì—¬ ì°¸ì¡° ëª¨ì…˜ í´ë¦½ì„ ìƒì„±í•œ ë‹¤ìŒ, ê°•í™”í•™ìŠµê³¼ í–‰ë™ ë³µì œ(RL+BC)ì˜ ì¡°í•©ì„ ì‚¬ìš©í•˜ì—¬ ê²¬ê³ í•˜ê³  ì ì‘ì ì´ë©° ë°˜ì‘ì„± ìˆëŠ” ì „ì‹  ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ ê°œë°œí•©ë‹ˆë‹¤. ì²´ê³„ì ì¸ ë¶„ì„ì„ í†µí•´ TWISTëŠ” íŠ¹ê¶Œì  ë¯¸ë˜ ëª¨ì…˜ í”„ë ˆì„ê³¼ ì‹¤ì œ ëª¨ì…˜ ìº¡ì²˜ ë°ì´í„°ë¥¼ í†µí•©í•˜ëŠ” ê²ƒì´ ì¶”ì  ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ ë‹¨ì¼ í†µí•© ì‹ ê²½ë§ ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì‹  ì¡°ì‘, ë‹¤ë¦¬ ì¡°ì‘, ì´ë™, í‘œí˜„ì  ì›€ì§ì„ì„ í¬ê´„í•˜ëŠ” ì „ë¡€ ì—†ì´ ë‹¤ì¬ë‹¤ëŠ¥í•˜ê³  í˜‘ì‘ëœ ì „ì‹  ìš´ë™ ê¸°ìˆ ì„ ì‹¤ì œ íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ì´ ë‹¬ì„±í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

### Key Features
- RL+BC hybrid training approach
- Whole-body motion retargeting from human MoCap
- Privileged future motion frame incorporation
- Versatile motor skills (manipulation, locomotion, expressive movement)
- Single unified neural network controller
- Real-time teleoperation capabilities

---

## Mobile-TeleVision: Predictive Motion Priors for Humanoid Whole-Body Control

**Authors**: Chenhao Lu, Xuxin Cheng, Jialong Li, Shiqi Yang, Mazeyu Ji, Chengjing Yuan, Ge Yang, Sha Yi, Xiaolong Wang

**Conference**: ICRA 2025

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2412.07773)
- ğŸŒ [Project](https://mobile-tv.github.io/)
- ğŸ’» [GitHub](https://github.com/OpenTeleVision/TeleVision)

### ìš”ì•½ (Summary)

 Mobile-TeleVision proposes decoupling upper-body control from locomotion, using inverse kinematics (IK) and motion retargeting for precise manipulation, while RL focuses on robust lower-body locomotion. The key innovation is PMP (Predictive Motion Priors), trained with Conditional Variational Autoencoder (CVAE) to effectively represent upper-body motions. The locomotion policy is trained conditioned on this upper-body motion representation, ensuring that the system remains robust with both manipulation and locomotion. The system significantly outperforms RL-based whole-body control in precise manipulation tasks.

 Mobile-TeleVisionì€ ìƒì²´ ì œì–´ë¥¼ ì´ë™ìœ¼ë¡œë¶€í„° ë¶„ë¦¬í•˜ì—¬, ì •ë°€ ì¡°ì‘ì„ ìœ„í•´ ì—­ìš´ë™í•™(IK)ê³¼ ëª¨ì…˜ ë¦¬íƒ€ê²ŒíŒ…ì„ ì‚¬ìš©í•˜ê³ , RLì€ ê²¬ê³ í•œ í•˜ì²´ ì´ë™ì— ì§‘ì¤‘í•˜ë„ë¡ ì œì•ˆí•©ë‹ˆë‹¤. í•µì‹¬ í˜ì‹ ì€ ì¡°ê±´ë¶€ ë³€ë¶„ ì˜¤í† ì¸ì½”ë”(CVAE)ë¡œ í›ˆë ¨ë˜ì–´ ìƒì²´ ë™ì‘ì„ íš¨ê³¼ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” PMP(ì˜ˆì¸¡ ëª¨ì…˜ ì‚¬ì „)ì…ë‹ˆë‹¤. ì´ë™ ì •ì±…ì€ ì´ ìƒì²´ ë™ì‘ í‘œí˜„ì— ì¡°ê±´í™”ë˜ì–´ í›ˆë ¨ë˜ë¯€ë¡œ, ì‹œìŠ¤í…œì´ ì¡°ì‘ê³¼ ì´ë™ ëª¨ë‘ì—ì„œ ê²¬ê³ í•˜ê²Œ ìœ ì§€ë©ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ ì •ë°€ ì¡°ì‘ ì‘ì—…ì—ì„œ RL ê¸°ë°˜ ì „ì‹  ì œì–´ë¥¼ í¬ê²Œ ëŠ¥ê°€í•©ë‹ˆë‹¤.

### Key Features
- Decoupled upper-body and lower-body control
- Predictive Motion Priors (PMP) with CVAE
- IK-based precise upper-body manipulation
- RL-based robust lower-body locomotion
- Superior manipulation precision vs. end-to-end RL
- Real-world deployment on Fourier GR1 and Unitree H1

---

## HOMIE: Humanoid Loco-Manipulation with Isomorphic Exoskeleton Cockpit

**Authors**: Qingwei Ben, Feiyu Jia, Jia Zeng, Junting Dong, Dahua Lin, Jiangmiao Pang

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2502.13013)
- ğŸŒ [Project](https://homietele.github.io/)
- ğŸ’» [GitHub](https://github.com/InternRobotics/OpenHomie)

### ìš”ì•½ (Summary)

**English**: HOMIE presents a humanoid loco-manipulation system using an isomorphic exoskeleton cockpit for teleoperation. The system enables intuitive whole-body control through a human-worn exoskeleton that mirrors the robot's morphology.

**í•œê¸€**: HOMIEëŠ” ì›ê²©ì¡°ì‘ì„ ìœ„í•œ ë™í˜• ì—‘ì†ŒìŠ¤ì¼ˆë ˆí†¤ ì¡°ì¢…ì„ì„ ì‚¬ìš©í•˜ëŠ” íœ´ë¨¸ë…¸ì´ë“œ ë¡œì½”-ë§¤ë‹ˆí“°ë ˆì´ì…˜ ì‹œìŠ¤í…œì„ ì œì‹œí•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ë¡œë´‡ì˜ í˜•íƒœë¥¼ ë°˜ì˜í•˜ëŠ” ì¸ê°„ì´ ì°©ìš©í•˜ëŠ” ì—‘ì†ŒìŠ¤ì¼ˆë ˆí†¤ì„ í†µí•´ ì§ê´€ì ì¸ ì „ì‹  ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

### Key Features
- Isomorphic exoskeleton design
- Whole-body loco-manipulation
- Intuitive teleoperation interface
- Real-time motion capture and control

---

## OmniH2O: Universal and Dexterous Human-to-Humanoid Whole-Body Teleoperation and Learning

**Authors**: Tairan He, Zhengyi Luo, Xialin He, Wenli Xiao, Chong Zhang, Weinan Zhang, Kris Kitani, Changliu Liu, Guanya Shi

**Conference**: CoRL 2024

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2406.08858)
- ğŸŒ [Project](https://omni.human2humanoid.com/)
- ğŸ’» [GitHub](https://github.com/LeCAR-Lab/human2humanoid)

### ìš”ì•½ (Summary)

 OmniH2O presents a learning-based system for whole-body humanoid teleoperation and autonomy. Using kinematic pose as a universal control interface, OmniH2O enables various ways for a human to control a full-sized humanoid with dexterous hands, including real-time teleoperation through VR headset, verbal instruction, and RGB camera. It also enables full autonomy by learning from teleoperated demonstrations or integrating with frontier models such as GPT-4. The system demonstrates versatility and dexterity in various real-world whole-body tasks such as playing multiple sports, moving and manipulating objects, and interacting with humans.

 OmniH2OëŠ” ì „ì‹  íœ´ë¨¸ë…¸ì´ë“œ ì›ê²©ì¡°ì‘ ë° ììœ¨ì„±ì„ ìœ„í•œ í•™ìŠµ ê¸°ë°˜ ì‹œìŠ¤í…œì„ ì œì‹œí•©ë‹ˆë‹¤. ìš´ë™í•™ì  í¬ì¦ˆë¥¼ ë²”ìš© ì œì–´ ì¸í„°í˜ì´ìŠ¤ë¡œ ì‚¬ìš©í•˜ì—¬, OmniH2OëŠ” VR í—¤ë“œì…‹, ìŒì„± ëª…ë ¹, RGB ì¹´ë©”ë¼ë¥¼ í†µí•œ ì‹¤ì‹œê°„ ì›ê²©ì¡°ì‘ì„ í¬í•¨í•˜ì—¬ ì¸ê°„ì´ ì •ë°€í•œ ì†ì„ ê°€ì§„ ì „ì‹  í¬ê¸° íœ´ë¨¸ë…¸ì´ë“œë¥¼ ì œì–´í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²•ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ë˜í•œ ì›ê²©ì¡°ì‘ ì‹œì—°ìœ¼ë¡œë¶€í„° í•™ìŠµí•˜ê±°ë‚˜ GPT-4ì™€ ê°™ì€ ìµœì²¨ë‹¨ ëª¨ë¸ê³¼ í†µí•©í•˜ì—¬ ì™„ì „í•œ ììœ¨ì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì€ ì—¬ëŸ¬ ìŠ¤í¬ì¸  ê²½ê¸°, ë¬¼ì²´ ì´ë™ ë° ì¡°ì‘, ì¸ê°„ê³¼ì˜ ìƒí˜¸ì‘ìš© ë“± ë‹¤ì–‘í•œ ì‹¤ì œ ì „ì‹  ì‘ì—…ì—ì„œ ë‹¤ì¬ë‹¤ëŠ¥í•¨ê³¼ ì •ë°€í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

### Key Features
- Universal kinematic pose control interface
- Multiple teleoperation modalities (VR, voice, camera)
- GPT-4 integration for autonomy
- Dexterous hand control
- OmniH2O-6 dataset (6 everyday tasks)
- Robust sim-to-real transfer pipeline

---
## H2O: Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation

**Authors**: Tairan He, Zhengyi Luo, Wenli Xiao, Chong Zhang, Kris Kitani, Changliu Liu, Guanya Shi

**Conference**: IROS 2024

**Links**:
- ğŸ“„ [arXiv](https://arxiv.org/abs/2403.04436)
- ğŸŒ [Project](https://human2humanoid.com/)
- ğŸ’» [GitHub](https://github.com/LeCAR-Lab/human2humanoid)

### ìš”ì•½ (Summary)

 H2O presents a reinforcement learning (RL) based framework that enables real-time whole-body teleoperation of a full-sized humanoid robot with only an RGB camera. To create a large-scale retargeted motion dataset, the paper proposes a scalable "sim-to-data" process to filter and pick feasible motions using a privileged motion imitator. The trained policy successfully achieves teleoperation of dynamic whole-body motions in real-world scenarios, including walking, back jumping, kicking, turning, waving, pushing, and boxing. This is the first demonstration to achieve learning-based real-time whole-body humanoid teleoperation.

 H2OëŠ” RGB ì¹´ë©”ë¼ë§Œìœ¼ë¡œ ì „ì‹  í¬ê¸° íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡ì˜ ì‹¤ì‹œê°„ ì „ì‹  ì›ê²©ì¡°ì‘ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê°•í™”í•™ìŠµ(RL) ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ëŒ€ê·œëª¨ ë¦¬íƒ€ê²ŒíŒ…ëœ ëª¨ì…˜ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ê¸° ìœ„í•´, ë…¼ë¬¸ì€ íŠ¹ê¶Œì  ëª¨ì…˜ ëª¨ë°©ìë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ëª¨ì…˜ì„ í•„í„°ë§í•˜ê³  ì„ íƒí•˜ëŠ” í™•ì¥ ê°€ëŠ¥í•œ "ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ë°ì´í„°ë¡œ" í”„ë¡œì„¸ìŠ¤ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. í›ˆë ¨ëœ ì •ì±…ì€ ê±·ê¸°, ë’¤ë¡œ ì í”„í•˜ê¸°, ì°¨ê¸°, ëŒê¸°, ì† í”ë“¤ê¸°, ë°€ê¸°, ë³µì‹±ì„ í¬í•¨í•œ ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë™ì  ì „ì‹  ë™ì‘ì˜ ì›ê²©ì¡°ì‘ì„ ì„±ê³µì ìœ¼ë¡œ ë‹¬ì„±í•©ë‹ˆë‹¤. ì´ê²ƒì€ í•™ìŠµ ê¸°ë°˜ ì‹¤ì‹œê°„ ì „ì‹  íœ´ë¨¸ë…¸ì´ë“œ ì›ê²©ì¡°ì‘ì„ ë‹¬ì„±í•œ ì²« ë²ˆì§¸ ì‹œì—°ì…ë‹ˆë‹¤.

### Key Features
- First real-time whole-body teleoperation via learning
- RGB camera-only system
- "Sim-to-data" motion filtering process
- Dynamic motion capabilities (jumping, kicking, boxing)
- Zero-shot sim-to-real transfer
- AMASS dataset utilization

---
[Back to Main README](../README.md)
